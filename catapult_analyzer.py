import undetected_chromedriver as uc
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
import logging
import re
from datetime import datetime
from collections import defaultdict
import time
import os

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


class CatapultAnalyzer:
    def __init__(self, headless=False):  # üîß –ó–ú–Ü–ù–ò–í –ù–ê False!
        self.driver = None
        self.all_tokens = []
        self.pattern_frequency = defaultdict(int)
        self.base_url = "https://catapult.trade"
        self.headless = headless
        self.display = None

    def init_virtual_display(self):
        """–ó–∞–ø—É—Å–∫–∞—î Virtual Display –¥–ª—è VPS"""
        if not self.headless or os.name != 'posix':
            return True
        
        try:
            from pyvirtualdisplay import Display
            self.display = Display(visible=0, size=(1920, 1080))
            self.display.start()
            logger.info("‚úÖ Virtual Display –∑–∞–ø—É—â–µ–Ω–∏–π")
            return True
        except:
            logger.warning("‚ö†Ô∏è Virtual Display –Ω–µ –¥–æ—Å—Ç—É–ø–Ω–∏–π")
            return True

    def init_driver(self):
        """–Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑—É—î –±—Ä–∞—É–∑–µ—Ä –ë–ï–ó headless –¥–ª—è JS —Ä–µ–Ω–¥–µ—Ä—É"""
        try:
            logger.info("üåê –ó–∞–ø—É—Å–∫–∞—é –±—Ä–∞—É–∑–µ—Ä...")

            options = uc.ChromeOptions()
            options.add_argument('--no-sandbox')
            options.add_argument('--disable-dev-shm-usage')
            options.add_argument('--disable-gpu')
            options.add_argument('--disable-blink-features=AutomationControlled')
            
            # üîß –ë–ï–ó --headless!
            if self.headless:
                options.add_argument('--virtual-display-size=1920x1080')
                logger.info("   üí° Virtual —Ä–µ–∂–∏–º")
            
            options.add_argument('--disable-extensions')
            options.add_argument('--disable-plugins')
            options.add_argument('--disable-background-networking')
            options.add_argument('--disable-breakpad')
            options.add_argument('--disable-client-side-phishing-detection')
            options.add_argument('--disable-default-apps')
            options.add_argument('--disable-hang-monitor')
            options.add_argument('--disable-popup-blocking')
            options.add_argument('--disable-prompt-on-repost')
            options.add_argument('--disable-sync')
            
            options.add_argument('user-agent=Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36')

            self.driver = uc.Chrome(options=options, version_main=None, use_subprocess=False)
            self.driver.set_page_load_timeout(50)
            
            logger.info("‚úÖ –ë—Ä–∞—É–∑–µ—Ä –∑–∞–ø—É—â–µ–Ω–∏–π")
            return True

        except Exception as e:
            logger.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –±—Ä–∞—É–∑–µ—Ä–∞: {e}")
            return False

    def fetch_page(self):
        """–ó–∞–≤–∞–Ω—Ç–∞–∂—É—î —Å—Ç–æ—Ä—ñ–Ω–∫—É —Ç–∞ —á–µ–∫–∞—î –Ω–∞ JS —Ä–µ–Ω–¥–µ—Ä"""
        try:
            logger.info("üìç –ó–∞–≤–∞–Ω—Ç–∞–∂–∞—é catapult.trade...")

            self.driver.get(f"{self.base_url}/turbo/home?sort=deployed_at_desc")

            logger.info("‚è≥ –ß–µ–∫–∞—é JS —Ä–µ–Ω–¥–µ—Ä (20 —Å–µ–∫)...")
            time.sleep(20)  # üîß –î–û–í–®–ï –ß–ï–ö–ê–Ñ–ú–û!

            # –ß–µ–∫–∞—î–º–æ –µ–ª–µ–º–µ–Ω—Ç–∏
            wait = WebDriverWait(self.driver, 25)
            try:
                wait.until(
                    EC.presence_of_all_elements_located(
                        (By.CSS_SELECTOR, "a[href*='/turbo/tokens/']")
                    )
                )
                logger.info("‚úÖ –ï–ª–µ–º–µ–Ω—Ç–∏ –∑–Ω–∞–π–¥–µ–Ω—ñ")
            except:
                logger.warning("‚ö†Ô∏è XPath timeout, –∞–ª–µ –ø—Ä–æ–¥–æ–≤–∂—É—é...")

            # –ê–≥—Ä–µ—Å–∏–≤–Ω–∏–π —Å–∫—Ä–æ–ª–ª–∏–Ω–≥
            logger.info("üìú –°–∫—Ä–æ–ª–ª—é —Ç–æ–∫–µ–Ω–∏...")
            for i in range(10):  # üîß –ë–Ü–õ–¨–®–ï –°–ö–†–û–õ–õ–Ü–í!
                self.driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
                time.sleep(1.5)

            # –ß–µ–∫–∞—î–º–æ —â–µ
            time.sleep(5)

            logger.info("‚úÖ –ì–æ—Ç–æ–≤–æ –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥—É")
            return self.driver.page_source

        except Exception as e:
            logger.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è: {e}")
            return None

    def extract_tokens(self, html: str):
        """–í–∏—Ç—è–≥—É—î —Ç–æ–∫–µ–Ω–∏ - —Å–ø—Ä–æ–±—É—î–º–æ –í–°–Ü –º–µ—Ç–æ–¥–∏"""
        try:
            from bs4 import BeautifulSoup
            soup = BeautifulSoup(html, 'lxml')

            tokens_found = []
            
            # –ú–µ—Ç–æ–¥ 1: CSS —Å–µ–ª–µ–∫—Ç–æ—Ä
            logger.info("   üîç –ú–µ—Ç–æ–¥ 1: CSS —Å–µ–ª–µ–∫—Ç–æ—Ä...")
            links = soup.find_all('a', href=re.compile(r'/turbo/tokens/'))
            logger.info(f"      ‚Üí –ó–Ω–∞–π–¥–µ–Ω–æ: {len(links)}")
            
            # –ú–µ—Ç–æ–¥ 2: –ü—Ä–æ—Å—Ç–æ —Ñ—ñ–ª—å—Ç—Ä
            if len(links) == 0:
                logger.info("   üîç –ú–µ—Ç–æ–¥ 2: –ü—Ä—è–º–∏–π —Ñ—ñ–ª—å—Ç—Ä...")
                all_a = soup.find_all('a')
                links = [a for a in all_a if a.get('href') and '/turbo/tokens/' in a.get('href', '')]
                logger.info(f"      ‚Üí –ó–Ω–∞–π–¥–µ–Ω–æ: {len(links)}")

            # –ú–µ—Ç–æ–¥ 3: –ü–æ data –∞—Ç—Ä–∏–±—É—Ç–∞–º
            if len(links) == 0:
                logger.info("   üîç –ú–µ—Ç–æ–¥ 3: Data –∞—Ç—Ä–∏–±—É—Ç–∏...")
                links = soup.select('a[href*="turbo/tokens"]')
                logger.info(f"      ‚Üí –ó–Ω–∞–π–¥–µ–Ω–æ: {len(links)}")

            logger.info(f"üìä –ò–¢–û–ì–û: {len(links)} –ø–æ—Å–∏–ª–∞–Ω—å –Ω–∞ —Ç–æ–∫–µ–Ω–∏")

            seen_urls = set()
            for link in links:
                href = link.get('href', '')
                if not href or href in seen_urls:
                    continue
                    
                if '/turbo/tokens/' not in href:
                    continue

                seen_urls.add(href)

                full_url = href if href.startswith('http') else f"{self.base_url}{href}"
                
                # –í–∏—Ç—è–≥—É—î–º–æ ID
                token_id_match = re.search(r'/tokens/(\d+)', href)
                token_id = token_id_match.group(1) if token_id_match else 'unknown'
                token_name = link.get_text(strip=True) or f"Token {token_id}"

                tokens_found.append({
                    'url': full_url,
                    'name': token_name,
                    'token_id': token_id
                })

            if tokens_found:
                logger.info(f"‚úÖ –í–∏—Ç—è–≥–Ω—É—Ç–æ {len(tokens_found)} —Ç–æ–∫–µ–Ω—ñ–≤")
            else:
                logger.warning("‚ö†Ô∏è –¢–û–ö–ï–ù–Ü–í –ù–ï –ó–ù–ê–ô–î–ï–ù–û!")
                logger.warning(f"   HTML —Ä–æ–∑–º—ñ—Ä: {len(html)} —Å–∏–º–≤–æ–ª—ñ–≤")
                
                # –î–µ–±–∞–≥
                if "Cloudflare" in html:
                    logger.warning("   ‚ö†Ô∏è CLOUDFLARE –í–ò–Ø–í–õ–ï–ù–ê!")
                
                all_links = soup.find_all('a', limit=30)
                logger.warning(f"   –í—Å—å–æ–≥–æ <a> —Ç–µ–≥—ñ–≤: {len(all_links)}")
                if all_links:
                    logger.warning("   –ü–µ—Ä—à—ñ 5 href:")
                    for i, l in enumerate(all_links[:5]):
                        logger.warning(f"      {i+1}. {l.get('href')}")

            return tokens_found[:25]

        except Exception as e:
            logger.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥—É: {e}")
            import traceback
            logger.error(traceback.format_exc())
            return []

    def analyze_token(self, token_url: str, token_id: str):
        """–ê–Ω–∞–ª—ñ–∑—É—î –æ–∫—Ä–µ–º–∏–π —Ç–æ–∫–µ–Ω"""
        token_data = {
            'url': token_url,
            'token_id': token_id,
            'name': '',
            'patterns': []
        }

        try:
            logger.info(f"   üîó Token #{token_id}")

            self.driver.get(token_url)
            time.sleep(3)

            html = self.driver.page_source

            from bs4 import BeautifulSoup
            soup = BeautifulSoup(html, 'lxml')
            title = soup.find('h1') or soup.find('title')
            if title:
                token_data['name'] = title.get_text(strip=True)[:50]

            # –ü–∞—Ç—Ç–µ—Ä–Ω–∏
            patterns = [
                ('‚è∞NEW', r'\bnew\b|\brecent\b|\blaunch\b'),
                ('üìàVOLUME', r'24h|volume|trading'),
                ('üîíLOCK', r'lock|locked|freeze|frozen'),
                ('üì±SOCIAL', r'telegram|twitter|discord|instagram'),
                ('üë•HOLDERS', r'(\d+(?:,\d+)*)\s+holders?'),
                ('üö®RUG', r'\brug\b|\bscam\b|\bhoneypot\b'),
                ('üìâDIP', r'\bdown\b|\bdip\b|\bcrash\b'),
                ('üí∞MCAP', r'market\s+cap|mcap'),
            ]

            for pattern_name, pattern_regex in patterns:
                if re.search(pattern_regex, html, re.I):
                    token_data['patterns'].append(pattern_name)
                    self.pattern_frequency[pattern_name] += 1

            pump_match = re.search(r'\+(\d+(?:\.\d+)?)\s*%', html)
            if pump_match:
                change = float(pump_match.group(1))
                if change >= 50:
                    token_data['patterns'].append('üöÄMEGA_PUMP')
                    self.pattern_frequency['üöÄMEGA_PUMP'] += 1
                elif change >= 20:
                    token_data['patterns'].append('üöÄPUMP')
                    self.pattern_frequency['üöÄPUMP'] += 1

            if token_data['patterns']:
                logger.info(f"      ‚úÖ {', '.join(token_data['patterns'][:3])}")

        except Exception as e:
            logger.debug(f"      ‚ö†Ô∏è {str(e)[:50]}")

        return token_data

    async def scan(self):
        """–û—Å–Ω–æ–≤–Ω–µ —Å–∫–∞–Ω—É–≤–∞–Ω–Ω—è"""
        logger.info("\n" + "=" * 70)
        logger.info(f"üîÑ –°–ö–ê–ù–£–í–ê–ù–ù–Ø CATAPULT - {datetime.now().strftime('%H:%M:%S')}")
        logger.info("=" * 70)

        # Virtual Display
        if not self.init_virtual_display():
            logger.error("‚ùå Virtual Display –ø–æ–º–∏–ª–∫–∞")

        if not self.init_driver():
            return {
                'timestamp': datetime.now().isoformat(),
                'total_tokens': 0,
                'total_patterns_found': 0,
                'top_patterns': [],
                'tokens': []
            }

        try:
            html = self.fetch_page()

            if not html:
                logger.error("‚ùå HTML –ø—É—Å—Ç")
                return {
                    'timestamp': datetime.now().isoformat(),
                    'total_tokens': 0,
                    'total_patterns_found': 0,
                    'top_patterns': [],
                    'tokens': []
                }

            tokens = self.extract_tokens(html)

            if not tokens:
                logger.warning("‚ö†Ô∏è –¢–æ–∫–µ–Ω—ñ–≤ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ - –ø–æ–≤–µ—Ä—Ç–∞—é –ø—É—Å—Ç–∏–π –∑–≤—ñ—Ç")
                return {
                    'timestamp': datetime.now().isoformat(),
                    'total_tokens': 0,
                    'total_patterns_found': 0,
                    'top_patterns': [],
                    'tokens': []
                }

            logger.info(f"üìä –ê–Ω–∞–ª—ñ–∑—É—é {len(tokens)} —Ç–æ–∫–µ–Ω—ñ–≤...")

            for token in tokens:
                token_data = self.analyze_token(token['url'], token['token_id'])
                if token_data['patterns']:
                    self.all_tokens.append(token_data)
                time.sleep(1)

            top_patterns = sorted(
                self.pattern_frequency.items(),
                key=lambda x: x[1],
                reverse=True
            )

            report = {
                'timestamp': datetime.now().isoformat(),
                'total_tokens': len(self.all_tokens),
                'total_patterns_found': sum(self.pattern_frequency.values()),
                'top_patterns': top_patterns,
                'tokens': self.all_tokens
            }

            logger.info("\n" + "=" * 70)
            logger.info(f"‚úÖ –ü–∞—Ç—Ç–µ—Ä–Ω—ñ–≤: {report['total_patterns_found']}")
            logger.info(f"üìä –¢–æ–∫–µ–Ω—ñ–≤: {report['total_tokens']}")
            logger.info("=" * 70 + "\n")

            return report

        finally:
            if self.driver:
                self.driver.quit()
                logger.info("üîå –ë—Ä–∞—É–∑–µ—Ä –∑–∞–∫—Ä–∏—Ç–∏–π")
            
            if self.display:
                self.display.stop()
                logger.info("üîå Virtual Display –∑–∞–∫—Ä–∏—Ç–∏–π")


async def scan_catapult():
    """–ü—É–±–ª—ñ—á–Ω–∞ —Ñ—É–Ω–∫—Ü—ñ—è"""
    analyzer = CatapultAnalyzer(headless=False)  # üîß False!
    return await analyzer.scan()
