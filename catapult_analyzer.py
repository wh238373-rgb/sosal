import undetected_chromedriver as uc
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
import json
import logging
import re
from datetime import datetime
from collections import defaultdict
import time
import os
import sys

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class CatapultAnalyzer:
    def __init__(self, headless=True, use_virtual_display=True):
        self.driver = None
        self.all_tokens = []
        self.pattern_frequency = defaultdict(int)
        self.base_url = "https://catapult.trade"
        self.headless = headless
        self.use_virtual_display = use_virtual_display
        self.display = None

    def init_virtual_display(self):
        """üñ•Ô∏è –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑—É—î Virtual Display –¥–ª—è VPS"""
        if not self.use_virtual_display:
            return True
            
        if os.name != 'posix':  # –¢—ñ–ª—å–∫–∏ –¥–ª—è Linux/Unix
            logger.info("‚ÑπÔ∏è Virtual Display –Ω–µ –ø–æ—Ç—Ä—ñ–±–µ–Ω –Ω–∞ —Ü—ñ–π —Å–∏—Å—Ç–µ–º—ñ")
            return True

        try:
            from pyvirtualdisplay import Display
            self.display = Display(visible=0, size=(1920, 1080))
            self.display.start()
            logger.info("‚úÖ Virtual Display –∑–∞–ø—É—â–µ–Ω–∏–π (1920x1080)")
            return True
        except ImportError:
            logger.warning("‚ö†Ô∏è pyvirtualdisplay –Ω–µ –≤—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–π, –ø—Ä–æ–¥–æ–≤–∂—É—é –±–µ–∑ –Ω—å–æ–≥–æ")
            return True
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –ü–æ–º–∏–ª–∫–∞ Virtual Display: {e}")
            return True

    def init_driver(self):
        """üåê –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑—É—î –±—Ä–∞—É–∑–µ—Ä –∑ –æ–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—î—é –¥–ª—è VPS"""
        try:
            logger.info("üåê –ó–∞–ø—É—Å–∫–∞—é –±—Ä–∞—É–∑–µ—Ä...")

            options = uc.ChromeOptions()
            
            # üîß –ë–∞–∑–æ–≤—ñ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏
            options.add_argument('--no-sandbox')
            options.add_argument('--disable-dev-shm-usage')
            options.add_argument('--disable-gpu')
            
            # üîß –î–ª—è VPS (headless mode)
            if self.headless:
                options.add_argument('--headless')
                options.add_argument('--disable-extensions')
                options.add_argument('--disable-plugins')
                options.add_argument('--disable-images')  # üìâ –®–≤–∏–¥—à–µ
                options.add_argument('--blink-settings=imagesEnabled=false')
                logger.info("   üí° Headless mode –∞–∫—Ç–∏–≤–æ–≤–∞–Ω–∏–π")
            else:
                options.add_argument('--start-maximized')

            # üîß –û–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—è –¥–ª—è VPS
            options.add_argument('--disable-web-resources')
            options.add_argument('--disable-default-apps')
            options.add_argument('--disable-translate')
            
            # üîß User-Agent —â–æ–± —É–Ω–∏–∫–Ω—É—Ç–∏ –±–ª–æ–∫—É–≤–∞–Ω–Ω—è
            options.add_argument(
                'user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) '
                'AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
            )

            logger.info("   ‚öôÔ∏è –ó–∞–ø—É—Å–∫–∞—é Chrome...")
            self.driver = uc.Chrome(
                options=options,
                version_main=None,
                use_subprocess=False  # üîß –ö—Ä–∞—â–µ –¥–ª—è VPS
            )
            
            # üîß Timeout –¥–ª—è –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è —Å—Ç–æ—Ä—ñ–Ω–æ–∫
            self.driver.set_page_load_timeout(30)
            
            logger.info("‚úÖ –ë—Ä–∞—É–∑–µ—Ä –∑–∞–ø—É—â–µ–Ω–∏–π —É—Å–ø—ñ—à–Ω–æ")
            return True

        except Exception as e:
            logger.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –±—Ä–∞—É–∑–µ—Ä–∞: {e}")
            return False

    def fetch_page(self):
        """üìç –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î —Å—Ç–æ—Ä—ñ–Ω–∫—É –∑ –æ–±—Ä–æ–±–∫–æ—é –ø–æ–º–∏–ª–æ–∫"""
        try:
            logger.info("üìç –ó–∞–≤–∞–Ω—Ç–∞–∂–∞—é catapult.trade/turbo/home...")

            self.driver.get(f"{self.base_url}/turbo/home?sort=deployed_at_desc")
            logger.info("   ‚è≥ –°—Ç–æ—Ä—ñ–Ω–∫–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–∞, —á–µ–∫–∞—é –∫–æ–Ω—Ç–µ–Ω—Ç—É...")

            wait = WebDriverWait(self.driver, 20)  # üîÑ –ó–±—ñ–ª—å—à–∏–≤ –¥–æ 20 —Å–µ–∫
            
            try:
                wait.until(
                    EC.presence_of_all_elements_located(
                        (By.XPATH, "//a[contains(@href, '/turbo/tokens/')]")
                    )
                )
                logger.info("   ‚úÖ –¢–æ–∫–µ–Ω–∏ –∑–∞–≥—Ä—É–∑–∏–ª–∏—Å—å")
            except:
                logger.warning("   ‚ö†Ô∏è –ß–µ–∫–∞–Ω–Ω—è —Å–∫—ñ–Ω—á–∏–ª–æ—Å—å, –∞–ª–µ –Ω–∞–º–∞–≥–∞—é—Å—å –¥–∞–ª—ñ...")
                # –ß–µ–∫–∞—î–º–æ —â–µ 5 —Å–µ–∫ –¥–ª—è JS —Ä–µ–Ω–¥–µ—Ä—É
                time.sleep(5)

            # üîß –°–∫—Ä–æ–ª–ª–∏–Ω–≥ –¥–ª—è –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –±—ñ–ª—å—à–µ —Ç–æ–∫–µ–Ω—ñ–≤
            logger.info("   üìú –°–∫—Ä–æ–ª–ª—é –¥–ª—è –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –¥–æ–¥–∞—Ç–∫–æ–≤–∏—Ö —Ç–æ–∫–µ–Ω—ñ–≤...")
            
            for i in range(4):  # üîÑ 4 –∑–∞–º—ñ—Å—Ç—å 5
                try:
                    self.driver.execute_script("window.scrollBy(0, 300)")
                    time.sleep(0.8)  # üîÑ –ú–µ–Ω—à–µ —á–∞—Å—É —á–µ–∫–∞–Ω–Ω—è
                except:
                    break

            logger.info("‚úÖ –°—Ç–æ—Ä—ñ–Ω–∫–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–∞")
            return self.driver.page_source

        except Exception as e:
            logger.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è: {e}")
            return None

    def extract_tokens(self, html: str):
        """üîç –í–∏—Ç—è–≥—É—î —Ç–æ–∫–µ–Ω–∏ –∑ –ø–µ—Ä–µ–≤—ñ—Ä–∫–æ—é —è–∫–æ—Å—Ç—ñ"""
        try:
            from bs4 import BeautifulSoup
            soup = BeautifulSoup(html, 'lxml')

            tokens_found = []
            links = soup.find_all('a', href=re.compile(r'/turbo/tokens/\d+'))

            logger.info(f"üìä –ó–Ω–∞–π–¥–µ–Ω–æ {len(links)} –ø–æ—Å–∏–ª–∞–Ω—å –Ω–∞ —Ç–æ–∫–µ–Ω–∏")

            seen_urls = set()

            for link in links:
                href = link.get('href', '')
                text = link.get_text(strip=True)

                if href and href not in seen_urls:
                    if re.search(r'/turbo/tokens/\d+', href):
                        seen_urls.add(href)

                        full_url = href if href.startswith('http') else f"{self.base_url}{href}"
                        
                        # üîß –ë–µ–∑–ø–µ—á–Ω–µ –≤–∏–¥–æ–±—É–≤–∞–Ω–Ω—è ID
                        token_id_match = re.search(r'/tokens/(\d+)', href)
                        token_id = token_id_match.group(1) if token_id_match else 'unknown'
                        token_name = text if text else f"Token {token_id}"

                        tokens_found.append({
                            'url': full_url,
                            'name': token_name,
                            'token_id': token_id
                        })

            if tokens_found:
                logger.info(f"‚úÖ –í–∏—Ç—è–≥–Ω—É—Ç–æ {len(tokens_found)} —Ä–µ–∞–ª—å–Ω–∏—Ö —Ç–æ–∫–µ–Ω—ñ–≤")
            else:
                logger.warning("‚ö†Ô∏è –†–µ–∞–ª—å–Ω–∏—Ö —Ç–æ–∫–µ–Ω—ñ–≤ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ")
                logger.debug(f"   HTML —Ä–æ–∑–º—ñ—Ä: {len(html)} —Å–∏–º–≤–æ–ª—ñ–≤")

            return tokens_found[:30]  # –ü–µ—Ä—à—ñ 30

        except Exception as e:
            logger.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥—É: {e}")
            return []

    def analyze_token(self, token_url: str, token_id: str):
        """üî¨ –ê–Ω–∞–ª—ñ–∑—É—î –æ–∫—Ä–µ–º–∏–π —Ç–æ–∫–µ–Ω"""
        token_data = {
            'url': token_url,
            'token_id': token_id,
            'name': '',
            'patterns': []
        }

        try:
            logger.info(f"   üîó –ê–Ω–∞–ª—ñ–∑—É—é Token #{token_id}")

            self.driver.get(token_url)
            time.sleep(2)  # üîÑ –ë—É–ª–æ 3, —Ç–µ–ø–µ—Ä 2

            html = self.driver.page_source

            from bs4 import BeautifulSoup
            soup = BeautifulSoup(html, 'lxml')
            
            # üìù –í–∏—Ç—è–≥—É—î–º–æ –Ω–∞–∑–≤—É
            title = soup.find('h1') or soup.find('title')
            if title:
                token_data['name'] = title.get_text(strip=True)[:50]

            # üîç –ü–ê–¢–¢–ï–†–ù–ò

            # ‚è∞ NEW
            if re.search(r'\bnew\b|\brecent\b|\blaunch\b', html, re.I):
                token_data['patterns'].append('‚è∞NEW')
                self.pattern_frequency['‚è∞NEW'] += 1

            # üöÄ PUMP
            pump_match = re.search(r'\+(\d+(?:\.\d+)?)\s*%', html)
            if pump_match:
                change = float(pump_match.group(1))
                if change >= 50:
                    token_data['patterns'].append('üöÄMEGA_PUMP')
                    self.pattern_frequency['üöÄMEGA_PUMP'] += 1
                elif change >= 20:
                    token_data['patterns'].append('üöÄPUMP')
                    self.pattern_frequency['üöÄPUMP'] += 1
                else:
                    token_data['patterns'].append('‚¨ÜÔ∏èUP')
                    self.pattern_frequency['‚¨ÜÔ∏èUP'] += 1

            # üìà VOLUME
            if re.search(r'24h|volume|trading', html, re.I):
                token_data['patterns'].append('üìàVOLUME')
                self.pattern_frequency['üìàVOLUME'] += 1

            # üîí LOCK
            if re.search(r'lock|locked|freeze|frozen', html, re.I):
                token_data['patterns'].append('üîíLOCK')
                self.pattern_frequency['üîíLOCK'] += 1

            # üì± SOCIAL
            if re.search(r'telegram|twitter|discord|instagram', html, re.I):
                token_data['patterns'].append('üì±SOCIAL')
                self.pattern_frequency['üì±SOCIAL'] += 1

            # üë• HOLDERS
            holders_match = re.search(r'(\d+(?:,\d+)*)\s+holders?', html, re.I)
            if holders_match:
                token_data['patterns'].append('üë•HOLDERS')
                self.pattern_frequency['üë•HOLDERS'] += 1

            # üö® RUG
            if re.search(r'\brug\b|\bscam\b|\bhoneypot\b|\bdanger\b|\brisk\b', html, re.I):
                token_data['patterns'].append('üö®RUG')
                self.pattern_frequency['üö®RUG'] += 1

            # üìâ DIP
            if re.search(r'\bdown\b|\bdip\b|\bcrash\b|\b-\d+%', html, re.I):
                token_data['patterns'].append('üìâDIP')
                self.pattern_frequency['üìâDIP'] += 1

            # üí∞ MCAP
            if re.search(r'market\s+cap|mcap|m\$', html, re.I):
                token_data['patterns'].append('üí∞MCAP')
                self.pattern_frequency['üí∞MCAP'] += 1

            # üíé HIGH_PRICE
            price_match = re.search(r'\$(\d+(?:,\d+)*(?:\.\d+)?)', html)
            if price_match:
                try:
                    price_str = price_match.group(1).replace(',', '')
                    price = float(price_str)
                    if price > 1:
                        token_data['patterns'].append('üíéHIGH_PRICE')
                        self.pattern_frequency['üíéHIGH_PRICE'] += 1
                except:
                    pass

            # ‚úÖ –õ–æ–≥—É–≤–∞–Ω–Ω—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤
            if token_data['patterns']:
                logger.info(f"      ‚úÖ {', '.join(token_data['patterns'][:3])}")
            else:
                logger.debug(f"      ‚ÑπÔ∏è –ü–∞—Ç—Ç–µ—Ä–Ω—ñ–≤ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ")

        except Exception as e:
            logger.debug(f"      ‚ö†Ô∏è –ü–æ–º–∏–ª–∫–∞: {str(e)[:50]}")

        return token_data

    async def scan(self):
        """üîÑ –û—Å–Ω–æ–≤–Ω–µ —Å–∫–∞–Ω—É–≤–∞–Ω–Ω—è"""
        logger.info("\n" + "=" * 70)
        logger.info(f"üîÑ –°–ö–ê–ù–£–í–ê–ù–ù–Ø CATAPULT - {datetime.now().strftime('%H:%M:%S')}")
        logger.info(f"   –†–µ–∂–∏–º: {'VPS (Headless)' if self.headless else 'Desktop'}")
        logger.info("=" * 70)

        # 1Ô∏è‚É£ Virtual Display
        if not self.init_virtual_display():
            logger.error("‚ùå –ù–µ –≤–¥–∞–ª–æ—Å—è —ñ–Ω—ñ—Ü—ñ–∞–ª—ñ–∑—É–≤–∞—Ç–∏ Virtual Display")

        # 2Ô∏è‚É£ –ë—Ä–∞—É–∑–µ—Ä
        if not self.init_driver():
            return self._empty_report()

        try:
            # 3Ô∏è‚É£ –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è —Å—ÇÔøΩÔøΩ—Ä—ñ–Ω–∫–∏
            html = self.fetch_page()
            if not html:
                return self._empty_report()

            # 4Ô∏è‚É£ –í–∏—Ç—è–≥–Ω–µ–Ω–Ω—è —Ç–æ–∫–µ–Ω—ñ–≤
            tokens = self.extract_tokens(html)
            if not tokens:
                logger.warning("‚ö†Ô∏è –†–µ–∞–ª—å–Ω–∏—Ö —Ç–æ–∫–µ–Ω—ñ–≤ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ")
                return self._empty_report()

            # 5Ô∏è‚É£ –ê–Ω–∞–ª—ñ–∑ —Ç–æ–∫–µ–Ω—ñ–≤
            logger.info(f"üìä –ê–Ω–∞–ª—ñ–∑—É—é {min(len(tokens), 12)} —Ç–æ–∫–µ–Ω—ñ–≤...")
            
            for idx, token in enumerate(tokens[:12], 1):  # üîÑ 12 –∑–∞–º—ñ—Å—Ç—å 15
                logger.info(f"   [{idx}/{min(len(tokens), 12)}]")
                token_data = self.analyze_token(token['url'], token['token_id'])
                if token_data['patterns']:
                    self.all_tokens.append(token_data)
                time.sleep(0.5)  # üîÑ –ú–µ–Ω—à–µ —á–∞—Å—É —á–µ–∫–∞–Ω–Ω—è

            # 6Ô∏è‚É£ –ì–µ–Ω–µ—Ä–∞—Ü—ñ—è –∑–≤—ñ—Ç—É
            top_patterns = sorted(
                self.pattern_frequency.items(),
                key=lambda x: x[1],
                reverse=True
            )

            report = {
                'timestamp': datetime.now().isoformat(),
                'total_tokens': len(self.all_tokens),
                'total_patterns_found': sum(self.pattern_frequency.values()),
                'top_patterns': top_patterns,
                'tokens': self.all_tokens
            }

            logger.info("\n" + "=" * 70)
            logger.info(f"‚úÖ –ó–Ω–∞–π–¥–µ–Ω–æ –ø–∞—Ç—Ç–µ—Ä–Ω—ñ–≤: {report['total_patterns_found']}")
            logger.info(f"üìä –ü—Ä–æ–∞–Ω–∞–ª—ñ–∑–æ–≤–∞–Ω–æ —Ç–æ–∫–µ–Ω—ñ–≤: {report['total_tokens']}")
            logger.info("=" * 70 + "\n")

            return report

        except Exception as e:
            logger.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –ø—ñ–¥ —á–∞—Å —Å–∫–∞–Ω—É–≤–∞–Ω–Ω—è: {e}")
            return self._empty_report()

        finally:
            # üîå –ó–∞–∫—Ä–∏—Ç—Ç—è
            self._cleanup()

    def _empty_report(self):
        """–ü–æ—Ä–æ–∂–Ω—ñ–π –∑–≤—ñ—Ç –ø—Ä–∏ –ø–æ–º–∏–ª—Ü—ñ"""
        return {
            'timestamp': datetime.now().isoformat(),
            'total_tokens': 0,
            'total_patterns_found': 0,
            'top_patterns': [],
            'tokens': []
        }

    def _cleanup(self):
        """üîå –û—á–∏—â–µ–Ω–Ω—è —Ä–µ—Å—É—Ä—Å—ñ–≤"""
        try:
            if self.driver:
                self.driver.quit()
                logger.info("üîå –ë—Ä–∞—É–∑–µ—Ä –∑–∞–∫—Ä–∏—Ç–∏–π")
        except:
            pass

        try:
            if self.display:
                self.display.stop()
                logger.info("üîå Virtual Display –∑—É–ø–∏–Ω–µ–Ω–∏–π")
        except:
            pass


async def scan_catapult(headless=True, use_virtual_display=True):
    """üì° –ü—É–±–ª—ñ—á–Ω–∞ —Ñ—É–Ω–∫—Ü—ñ—è –¥–ª—è –∑–∞–ø—É—Å–∫—É"""
    analyzer = CatapultAnalyzer(headless=headless, use_virtual_display=use_virtual_display)
    return await analyzer.scan()
